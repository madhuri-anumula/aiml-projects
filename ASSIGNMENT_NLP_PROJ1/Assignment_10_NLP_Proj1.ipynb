{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w__S-pdKbp07"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkJAQRptbvf5"
   },
   "source": [
    "\n",
    "# **Assignment_NLP_Proj1_Madhuri.A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gKXpUID3m4G"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i590L387cO2"
   },
   "outputs": [],
   "source": [
    "## PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvYXb_apmbeF",
    "outputId": "8b20349b-5be3-41b9-aca7-0f333c912af7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "nltk.download('all')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "import random\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import tensorflow as tensorF \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNUSu1oIsE2-",
    "outputId": "f6401fb1-0e22-4704-e74e-084fe64f7995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk downloaded (run only once)\n",
    "nltk.download('stopwords',quiet=True) # stopword library\n",
    "nltk.download('wordnet', quiet=True) # wordnet library\n",
    "nltk.download('words', quiet=True) # words library\n",
    "nltk.download('punkt', quiet=True) # tokenize library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4CyQUas3qfw"
   },
   "outputs": [],
   "source": [
    "##1.Read and Analyse Dataset. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5UTaVgAFkO0f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQkYDtY8khCs",
    "outputId": "c3c48c1d-b905-40ca-ca08-e24ff43d1768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fq2A2TtMkpXF"
   },
   "outputs": [],
   "source": [
    "project_path = ''\n",
    "dataset_file = project_path + '/content/drive/My Drive/Colab Notebooks/blogs.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gyBoeWd-kv-E"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(dataset_file,'r') as zip:\n",
    "  zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnpOYfGTlqAK",
    "outputId": "0cad49b9-e8aa-49b6-ea37-1092421776e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blogtext.csv  drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIKA6ieekzlJ",
    "outputId": "992d6090-0883-4f75-960e-fbb1d772cca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681284, 7)\n"
     ]
    }
   ],
   "source": [
    "blogtext_df = pd.read_csv('blogtext.csv',na_values = ' ')\n",
    "print(blogtext_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12vWXfnynRcP",
    "outputId": "f269798a-90ee-4933-d6d8-0d95975bc613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogtext_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v1f2RJunUsq",
    "outputId": "5621aee6-f914-47b9-bd4d-87d25658af9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogtext_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "szCTVdDHndAi",
    "outputId": "29ada082-0f5d-4f58-f95b-1d1bad36f0dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ecfaf29e-55d5-441e-9d49-1be5e32292f2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4172416</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>08,August,2004</td>\n",
       "      <td>urlLink     im new to this, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4172416</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>08,August,2004</td>\n",
       "      <td>Election time has rolled aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3668238</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>30,June,2004</td>\n",
       "      <td>http://www.uploadimages.net/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3668238</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>26,June,2004</td>\n",
       "      <td>it was fun :)  Hey dad       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3668238</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>24,June,2004</td>\n",
       "      <td>war is every why are we so fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecfaf29e-55d5-441e-9d49-1be5e32292f2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ecfaf29e-55d5-441e-9d49-1be5e32292f2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ecfaf29e-55d5-441e-9d49-1be5e32292f2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         id  gender  age              topic       sign            date  \\\n",
       "0   2059027    male   15            Student        Leo     14,May,2004   \n",
       "1   2059027    male   15            Student        Leo     13,May,2004   \n",
       "2   2059027    male   15            Student        Leo     12,May,2004   \n",
       "3   2059027    male   15            Student        Leo     12,May,2004   \n",
       "4   3581210    male   33  InvestmentBanking   Aquarius    11,June,2004   \n",
       "..      ...     ...  ...                ...        ...             ...   \n",
       "95  4172416  female   25             indUnk  Capricorn  08,August,2004   \n",
       "96  4172416  female   25             indUnk  Capricorn  08,August,2004   \n",
       "97  3668238  female   17            Student     Gemini    30,June,2004   \n",
       "98  3668238  female   17            Student     Gemini    26,June,2004   \n",
       "99  3668238  female   17            Student     Gemini    24,June,2004   \n",
       "\n",
       "                                                 text  \n",
       "0              Info has been found (+/- 100 pages,...  \n",
       "1              These are the team members:   Drewe...  \n",
       "2              In het kader van kernfusie op aarde...  \n",
       "3                    testing!!!  testing!!!            \n",
       "4                Thanks to Yahoo!'s Toolbar I can ...  \n",
       "..                                                ...  \n",
       "95                    urlLink     im new to this, ...  \n",
       "96                    Election time has rolled aro...  \n",
       "97                   http://www.uploadimages.net/i...  \n",
       "98                   it was fun :)  Hey dad       ...  \n",
       "99                   war is every why are we so fi...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogtext_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "UOOJm3mmuj2O",
    "outputId": "35741126-a047-4ec9-d0ab-d9ced09c590b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8dc4ba59-ee45-4f6d-9f3f-b860ffc2ff00\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157994</th>\n",
       "      <td>3468490</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>06,June,2004</td>\n",
       "      <td>urlLink    paLawaN beacH  urlLink     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172566</th>\n",
       "      <td>3588087</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>urlLink    This is part of the grounds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172567</th>\n",
       "      <td>3588087</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>urlLink    There is a boat you can tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172568</th>\n",
       "      <td>3588087</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>urlLink    Our first evening there, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172569</th>\n",
       "      <td>3588087</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>03,July,2004</td>\n",
       "      <td>urlLink    After my initial shock over...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dc4ba59-ee45-4f6d-9f3f-b860ffc2ff00')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8dc4ba59-ee45-4f6d-9f3f-b860ffc2ff00 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8dc4ba59-ee45-4f6d-9f3f-b860ffc2ff00');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             id  gender  age              topic         sign          date  \\\n",
       "0       2059027    male   15            Student          Leo   14,May,2004   \n",
       "1       2059027    male   15            Student          Leo   13,May,2004   \n",
       "2       2059027    male   15            Student          Leo   12,May,2004   \n",
       "3       2059027    male   15            Student          Leo   12,May,2004   \n",
       "4       3581210    male   33  InvestmentBanking     Aquarius  11,June,2004   \n",
       "...         ...     ...  ...                ...          ...           ...   \n",
       "157994  3468490    male   14        Environment  Sagittarius  06,June,2004   \n",
       "172566  3588087  female   26        Environment       Pisces  03,July,2004   \n",
       "172567  3588087  female   26        Environment       Pisces  03,July,2004   \n",
       "172568  3588087  female   26        Environment       Pisces  03,July,2004   \n",
       "172569  3588087  female   26        Environment       Pisces  03,July,2004   \n",
       "\n",
       "                                                     text  \n",
       "0                  Info has been found (+/- 100 pages,...  \n",
       "1                  These are the team members:   Drewe...  \n",
       "2                  In het kader van kernfusie op aarde...  \n",
       "3                        testing!!!  testing!!!            \n",
       "4                    Thanks to Yahoo!'s Toolbar I can ...  \n",
       "...                                                   ...  \n",
       "157994          urlLink    paLawaN beacH  urlLink     ...  \n",
       "172566          urlLink    This is part of the grounds...  \n",
       "172567          urlLink    There is a boat you can tak...  \n",
       "172568          urlLink    Our first evening there, we...  \n",
       "172569          urlLink    After my initial shock over...  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_class_df = blogtext_df.groupby(['topic'])\n",
    "group_by_class_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0sYh4cGu-OI",
    "outputId": "a3d898d2-7952-4573-a8ce-4265d8b514a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blogtext_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmGOaXcbtEhJ",
    "outputId": "89181f1b-61f1-4fa9-92b5-f42e1b3b057c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Student', 'InvestmentBanking', 'indUnk', 'Non-Profit', 'Banking',\n",
       "       'Education', 'Engineering', 'Science', 'Communications-Media',\n",
       "       'BusinessServices', 'Sports-Recreation', 'Arts', 'Internet',\n",
       "       'Museums-Libraries', 'Accounting', 'Technology', 'Law',\n",
       "       'Consulting', 'Automotive', 'Religion', 'Fashion', 'Publishing',\n",
       "       'Marketing', 'LawEnforcement-Security', 'HumanResources',\n",
       "       'Telecommunications', 'Military', 'Government', 'Transportation',\n",
       "       'Architecture', 'Advertising', 'Agriculture', 'Biotech',\n",
       "       'RealEstate', 'Manufacturing', 'Construction', 'Chemicals',\n",
       "       'Maritime', 'Tourism', 'Environment'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogtext_df['topic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ukr8rV133KJ"
   },
   "outputs": [],
   "source": [
    "#A.Clearly write outcome of data analysis(Minimum 2 points) [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nq68FeI5nh7s",
    "outputId": "6bb438bd-646a-4c95-c5f9-b544a66ff615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations/Analysis:\n",
      "1) This consolidated CSV file contains  articles on different topics like student,investment banking,agriculture etc.\n",
      "2) Details like gender,age, sun sign, date of blog written are stored in addition to the blog text.\n",
      "3) Blogger is identified by the id and has written multiple blogs on different topics. Eg: Userid - 3588087, has multiple blogs on environment.\n",
      "4. There are 19320 bloggers. \n"
     ]
    }
   ],
   "source": [
    "print(\"Observations/Analysis:\")\n",
    "print(\"1) This consolidated CSV file contains  articles on different topics like student,investment banking,agriculture etc.\")\n",
    "print(\"2) Details like gender,age, sun sign, date of blog written are stored in addition to the blog text.\") \n",
    "print(\"3) Blogger is identified by the id and has written multiple blogs on different topics. Eg: Userid - 3588087, has multiple blogs on environment.\")\n",
    "print(\"4. There are 19320 bloggers. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "o_CzZDL4mE_P"
   },
   "outputs": [],
   "source": [
    "#Reducing the same size to .02 fraction for faster execution on the classifier models\n",
    "# generating one row \n",
    "blogs_sample_df = blogtext_df.sample(frac =.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n69KoRKpmh0A",
    "outputId": "1a980b88-bc1c-48c3-f87d-7b487a53c443"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13626, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9g_zHc6lDAx",
    "outputId": "88c14d1a-121d-4607-8931-774b4de523da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfEybTVA37WR"
   },
   "outputs": [],
   "source": [
    "#B.Clean the Structured Data [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfdbPaKx3_Hp"
   },
   "outputs": [],
   "source": [
    "#i.Missing value analysis and imputation. [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "O3Jq6Pxihp4R",
    "outputId": "906069f8-07b6-4a7a-f9aa-85454f674ca2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9a08ee82-016d-4ed9-909e-2ea37249d834\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>id</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>age</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <td>topic</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sign</th>\n",
       "      <td>sign</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>date</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>text</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a08ee82-016d-4ed9-909e-2ea37249d834')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9a08ee82-016d-4ed9-909e-2ea37249d834 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9a08ee82-016d-4ed9-909e-2ea37249d834');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       column_name  percent_missing\n",
       "id              id              0.0\n",
       "gender      gender              0.0\n",
       "age            age              0.0\n",
       "topic        topic              0.0\n",
       "sign          sign              0.0\n",
       "date          date              0.0\n",
       "text          text              0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_feature_missing = blogs_sample_df.isnull().sum() * 100 / len(blogs_sample_df)\n",
    "missing_data_value_df = pd.DataFrame({'column_name': blogs_sample_df.columns,\n",
    "                                 'percent_missing': percent_feature_missing})\n",
    "missing_data_value_df\n",
    "\n",
    "#print(\"No missing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GXrs9n5ieZW",
    "outputId": "d7cb2ccd-bf0f-4fe8-e562-dcb7fca04e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing data\n"
     ]
    }
   ],
   "source": [
    "print(\"No missing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "O70bn1Oh4AG_"
   },
   "outputs": [],
   "source": [
    "#ii.Eliminate Non-English textual data. [2 Marks]\n",
    "#Hint: Refer ‘langdetect’ library to detect language of the input text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vm08Arpf6bIm",
    "outputId": "78523b4b-c076-4ceb-9a3f-df92d9ecff3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5seOQz4LjcRH"
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_english(text):\n",
    "  try:\n",
    "      return detect(text) == 'en'\n",
    "  except:\n",
    "      return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "L_eRQisIjQdI"
   },
   "outputs": [],
   "source": [
    "blogs_sample_df = blogs_sample_df[blogs_sample_df['text'].apply(detect_english)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t6zVmFGNj5Cu",
    "outputId": "1a59d5a0-05f9-4af2-8006-f855f76d4bf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13007, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxcOtPVW4YFX"
   },
   "outputs": [],
   "source": [
    "##2. Preprocess unstructured data to make it consumable for model training. [5 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjM4o3Fn4hEi"
   },
   "outputs": [],
   "source": [
    "#A.Eliminate All special Characters and Numbers [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "e8gU8ahgorEV"
   },
   "outputs": [],
   "source": [
    "def remove_special_chars_and_digits(text):\n",
    "    return re.sub(\"(\\\\d|\\\\W)+\",\" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rLBmLsnmpoAv"
   },
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    text = remove_special_chars_and_digits(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d2AeC7ZpqDbh",
    "outputId": "7bb52153-db45-47a0-ee5c-a3d339e1f668"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-30873213-7e54-48f4-9854-8f8fe522321e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538461</th>\n",
       "      <td>I wasn't going to do this, but I ...</td>\n",
       "      <td>I wasn t going to do this but I have no choic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340758</th>\n",
       "      <td>Im looking at this fine dir...</td>\n",
       "      <td>Im looking at this fine director and thinking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445747</th>\n",
       "      <td>Well, this was rather surprising. I we...</td>\n",
       "      <td>Well this was rather surprising I went to pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652503</th>\n",
       "      <td>It was the last one. We picked it up n ...</td>\n",
       "      <td>It was the last one We picked it up n started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568568</th>\n",
       "      <td>now for a random thoughtful excerpt...</td>\n",
       "      <td>now for a random thoughtful excerpt from a ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371507</th>\n",
       "      <td>I totally forgot that I had won (again)...</td>\n",
       "      <td>I totally forgot that I had won again two tic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157822</th>\n",
       "      <td>&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp...</td>\n",
       "      <td>nbsp nbsp nbsp nbsp nbsp I ask that you all b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53976</th>\n",
       "      <td>Today Marie called and said that ...</td>\n",
       "      <td>Today Marie called and said that her relation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303516</th>\n",
       "      <td>Just for all of you wondering, the old ...</td>\n",
       "      <td>Just for all of you wondering the old Amy Luh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258329</th>\n",
       "      <td>yay im really happy rite now. For chris...</td>\n",
       "      <td>yay im really happy rite now For christmas se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92694</th>\n",
       "      <td>I am now the proud owner of Big Fish, w...</td>\n",
       "      <td>I am now the proud owner of Big Fish well a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433407</th>\n",
       "      <td>I bought a new CD today! :D This on...</td>\n",
       "      <td>I bought a new CD today D This one Definitely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182139</th>\n",
       "      <td>It's Debbie's birthday today. Just sen...</td>\n",
       "      <td>It s Debbie s birthday today Just sent her an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469799</th>\n",
       "      <td>hallo from gw. back in d.c. :)</td>\n",
       "      <td>hallo from gw back in d c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557677</th>\n",
       "      <td>The last thing that this movie is going...</td>\n",
       "      <td>The last thing that this movie is going to ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357219</th>\n",
       "      <td>.     Well..I finally got the title...</td>\n",
       "      <td>Well I finally got the title to the car I bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50085</th>\n",
       "      <td>urlLink    My cousin Andy and Grandma ...</td>\n",
       "      <td>urlLink My cousin Andy and Grandma Marjorie m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616996</th>\n",
       "      <td>But I'd miss novels, alcohol, nicotine,...</td>\n",
       "      <td>But I d miss novels alcohol nicotine swearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362231</th>\n",
       "      <td>The bluest skies you’ve ever seen...</td>\n",
       "      <td>The bluest skies you ve ever seen are in Seat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414846</th>\n",
       "      <td>urlLink More Pictures  -- from bef...</td>\n",
       "      <td>urlLink More Pictures from before May th So t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108572</th>\n",
       "      <td>I'm December too: Loyal and generou...</td>\n",
       "      <td>I m December too Loyal and generous I like to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238524</th>\n",
       "      <td>Personal Ad   'SINGLE BLACK FEMA...</td>\n",
       "      <td>Personal Ad SINGLE BLACK FEMALE Seeks male co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306514</th>\n",
       "      <td>haix.. reallie si be...</td>\n",
       "      <td>haix reallie si bei sianx lehx sian until now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497631</th>\n",
       "      <td>ok, so i visited a blog called bigwhite...</td>\n",
       "      <td>ok so i visited a blog called bigwhiteguy com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469308</th>\n",
       "      <td>(yeah, i cheated and checked at webster...</td>\n",
       "      <td>yeah i cheated and checked at webster com fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269088</th>\n",
       "      <td>urlLink Mac OS X 10.3 Panther (11/...</td>\n",
       "      <td>urlLink Mac OS X Panther Arstechnica has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78447</th>\n",
       "      <td>urlLink    goofing off at lunch&amp;nbsp; ...</td>\n",
       "      <td>urlLink goofing off at lunch nbsp urlLink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205970</th>\n",
       "      <td>1st official entry:  Today: At offi...</td>\n",
       "      <td>st official entry Today At office working on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465466</th>\n",
       "      <td>Oi! Nutters!  Today was kinda fun and k...</td>\n",
       "      <td>Oi Nutters Today was kinda fun and kinda sad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441430</th>\n",
       "      <td>&amp;nbsp; breaky - half bowl of ...</td>\n",
       "      <td>nbsp breaky half bowl of Coco pops w full cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419646</th>\n",
       "      <td>Steph, I'm so sorry to hear about...</td>\n",
       "      <td>Steph I m so sorry to hear about your uncle I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227517</th>\n",
       "      <td>This weekend I will be at  urlLink ...</td>\n",
       "      <td>This weekend I will be at urlLink Kraftwerk Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410323</th>\n",
       "      <td>Happy Birthday Nutter Butter!...</td>\n",
       "      <td>Happy Birthday Nutter Butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502785</th>\n",
       "      <td>Batacumbele - Yoruba language meaning ...</td>\n",
       "      <td>Batacumbele Yoruba language meaning to kneel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220667</th>\n",
       "      <td>CAPTAIN Jack Sparrow: Very Interesting....</td>\n",
       "      <td>CAPTAIN Jack Sparrow Very Interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>right now, i have on no shoes.  no ...</td>\n",
       "      <td>right now i have on no shoes no shirt and yet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189239</th>\n",
       "      <td>Special thanks go out to  urlLink Brent...</td>\n",
       "      <td>Special thanks go out to urlLink Brent for ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111732</th>\n",
       "      <td>HOLLA 1983...I think it's year of the d...</td>\n",
       "      <td>HOLLA I think it s year of the dog Ruff I thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70625</th>\n",
       "      <td>its the only way to eat it. yum. left o...</td>\n",
       "      <td>its the only way to eat it yum left over nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673603</th>\n",
       "      <td>Stewart,},  -- abolition,i must counter...</td>\n",
       "      <td>Stewart abolition i must counter abolition i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297213</th>\n",
       "      <td>Hmmm....,           Intizaar is bac...</td>\n",
       "      <td>Hmmm Intizaar is back people Well i m going f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366161</th>\n",
       "      <td>Amanda is one of the few chick...</td>\n",
       "      <td>Amanda is one of the few chick rockers that I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503367</th>\n",
       "      <td>It's the worst feeling in the world...</td>\n",
       "      <td>It s the worst feeling in the world the one t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103027</th>\n",
       "      <td>posted by Bruce Baugh                   ...</td>\n",
       "      <td>posted by Bruce Baugh urlLink Drive Thru RPG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54802</th>\n",
       "      <td>I AM sOOOOOO Freaking PISSED!...</td>\n",
       "      <td>I AM sOOOOOO Freaking PISSED My mom and step ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529984</th>\n",
       "      <td>My life is so screwed up right now. My ...</td>\n",
       "      <td>My life is so screwed up right now My emotion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196162</th>\n",
       "      <td>Wow! That's great! Both The Mac Shac &amp; ...</td>\n",
       "      <td>Wow That s great Both The Mac Shac The Self D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574594</th>\n",
       "      <td>Baseball is here. Too bad the Cardinals...</td>\n",
       "      <td>Baseball is here Too bad the Cardinals weren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451262</th>\n",
       "      <td>What is life, but an accrual of experie...</td>\n",
       "      <td>What is life but an accrual of experiences yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474965</th>\n",
       "      <td>I just finished the Virgin Suicid...</td>\n",
       "      <td>I just finished the Virgin Suicides Interesti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30873213-7e54-48f4-9854-8f8fe522321e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-30873213-7e54-48f4-9854-8f8fe522321e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-30873213-7e54-48f4-9854-8f8fe522321e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "538461               I wasn't going to do this, but I ...   \n",
       "340758                     Im looking at this fine dir...   \n",
       "445747          Well, this was rather surprising. I we...   \n",
       "652503         It was the last one. We picked it up n ...   \n",
       "568568             now for a random thoughtful excerpt...   \n",
       "371507         I totally forgot that I had won (again)...   \n",
       "157822                   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp...   \n",
       "53976                Today Marie called and said that ...   \n",
       "303516         Just for all of you wondering, the old ...   \n",
       "258329         yay im really happy rite now. For chris...   \n",
       "92694          I am now the proud owner of Big Fish, w...   \n",
       "433407             I bought a new CD today! :D This on...   \n",
       "182139          It's Debbie's birthday today. Just sen...   \n",
       "469799           hallo from gw. back in d.c. :)             \n",
       "557677         The last thing that this movie is going...   \n",
       "357219             .     Well..I finally got the title...   \n",
       "50085           urlLink    My cousin Andy and Grandma ...   \n",
       "616996         But I'd miss novels, alcohol, nicotine,...   \n",
       "362231               The bluest skies you’ve ever seen...   \n",
       "414846              urlLink More Pictures  -- from bef...   \n",
       "108572             I'm December too: Loyal and generou...   \n",
       "238524                Personal Ad   'SINGLE BLACK FEMA...   \n",
       "306514                            haix.. reallie si be...   \n",
       "497631         ok, so i visited a blog called bigwhite...   \n",
       "469308         (yeah, i cheated and checked at webster...   \n",
       "269088              urlLink Mac OS X 10.3 Panther (11/...   \n",
       "78447           urlLink    goofing off at lunch&nbsp; ...   \n",
       "205970             1st official entry:  Today: At offi...   \n",
       "465466         Oi! Nutters!  Today was kinda fun and k...   \n",
       "441430                   &nbsp; breaky - half bowl of ...   \n",
       "419646               Steph, I'm so sorry to hear about...   \n",
       "227517             This weekend I will be at  urlLink ...   \n",
       "410323                   Happy Birthday Nutter Butter!...   \n",
       "502785          Batacumbele - Yoruba language meaning ...   \n",
       "220667         CAPTAIN Jack Sparrow: Very Interesting....   \n",
       "2885               right now, i have on no shoes.  no ...   \n",
       "189239         Special thanks go out to  urlLink Brent...   \n",
       "111732         HOLLA 1983...I think it's year of the d...   \n",
       "70625          its the only way to eat it. yum. left o...   \n",
       "673603         Stewart,},  -- abolition,i must counter...   \n",
       "297213             Hmmm....,           Intizaar is bac...   \n",
       "366161                  Amanda is one of the few chick...   \n",
       "503367             It's the worst feeling in the world...   \n",
       "103027        posted by Bruce Baugh                   ...   \n",
       "54802                    I AM sOOOOOO Freaking PISSED!...   \n",
       "529984         My life is so screwed up right now. My ...   \n",
       "196162         Wow! That's great! Both The Mac Shac & ...   \n",
       "574594         Baseball is here. Too bad the Cardinals...   \n",
       "451262         What is life, but an accrual of experie...   \n",
       "474965               I just finished the Virgin Suicid...   \n",
       "\n",
       "                                          normalized_text  \n",
       "538461   I wasn t going to do this but I have no choic...  \n",
       "340758   Im looking at this fine director and thinking...  \n",
       "445747   Well this was rather surprising I went to pos...  \n",
       "652503   It was the last one We picked it up n started...  \n",
       "568568   now for a random thoughtful excerpt from a ch...  \n",
       "371507   I totally forgot that I had won again two tic...  \n",
       "157822   nbsp nbsp nbsp nbsp nbsp I ask that you all b...  \n",
       "53976    Today Marie called and said that her relation...  \n",
       "303516   Just for all of you wondering the old Amy Luh...  \n",
       "258329   yay im really happy rite now For christmas se...  \n",
       "92694    I am now the proud owner of Big Fish well a c...  \n",
       "433407   I bought a new CD today D This one Definitely...  \n",
       "182139   It s Debbie s birthday today Just sent her an...  \n",
       "469799                         hallo from gw back in d c   \n",
       "557677   The last thing that this movie is going to ne...  \n",
       "357219   Well I finally got the title to the car I bou...  \n",
       "50085    urlLink My cousin Andy and Grandma Marjorie m...  \n",
       "616996   But I d miss novels alcohol nicotine swearing...  \n",
       "362231   The bluest skies you ve ever seen are in Seat...  \n",
       "414846   urlLink More Pictures from before May th So t...  \n",
       "108572   I m December too Loyal and generous I like to...  \n",
       "238524   Personal Ad SINGLE BLACK FEMALE Seeks male co...  \n",
       "306514   haix reallie si bei sianx lehx sian until now...  \n",
       "497631   ok so i visited a blog called bigwhiteguy com...  \n",
       "469308   yeah i cheated and checked at webster com fir...  \n",
       "269088   urlLink Mac OS X Panther Arstechnica has been...  \n",
       "78447          urlLink goofing off at lunch nbsp urlLink   \n",
       "205970   st official entry Today At office working on ...  \n",
       "465466   Oi Nutters Today was kinda fun and kinda sad ...  \n",
       "441430   nbsp breaky half bowl of Coco pops w full cre...  \n",
       "419646   Steph I m so sorry to hear about your uncle I...  \n",
       "227517   This weekend I will be at urlLink Kraftwerk Y...  \n",
       "410323                      Happy Birthday Nutter Butter   \n",
       "502785   Batacumbele Yoruba language meaning to kneel ...  \n",
       "220667             CAPTAIN Jack Sparrow Very Interesting   \n",
       "2885     right now i have on no shoes no shirt and yet...  \n",
       "189239   Special thanks go out to urlLink Brent for ho...  \n",
       "111732   HOLLA I think it s year of the dog Ruff I thi...  \n",
       "70625    its the only way to eat it yum left over nice...  \n",
       "673603   Stewart abolition i must counter abolition i ...  \n",
       "297213   Hmmm Intizaar is back people Well i m going f...  \n",
       "366161   Amanda is one of the few chick rockers that I...  \n",
       "503367   It s the worst feeling in the world the one t...  \n",
       "103027   posted by Bruce Baugh urlLink Drive Thru RPG ...  \n",
       "54802    I AM sOOOOOO Freaking PISSED My mom and step ...  \n",
       "529984   My life is so screwed up right now My emotion...  \n",
       "196162   Wow That s great Both The Mac Shac The Self D...  \n",
       "574594   Baseball is here Too bad the Cardinals weren ...  \n",
       "451262   What is life but an accrual of experiences yo...  \n",
       "474965   I just finished the Virgin Suicides Interesti...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new feature with normalized text\n",
    "\n",
    "blogs_sample_df['normalized_text'] = blogs_sample_df['text'].apply(normalize_text)\n",
    "blogs_sample_df.loc[:, ['text', 'normalized_text']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wS72xOw4jfc"
   },
   "outputs": [],
   "source": [
    "#B.Lowercase all textual data [1 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jm6U3SrbqurV"
   },
   "outputs": [],
   "source": [
    "\n",
    "def lower_case(text):\n",
    "    return text.lower()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5ef2SeOwq5eg"
   },
   "outputs": [],
   "source": [
    "def normalize_lower_case(text: str) -> str:\n",
    "    text = lower_case(text)\n",
    " \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9kgKC4FBrEqb",
    "outputId": "58342488-2904-461a-b233-2e984a3ab4eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1250ee2e-64be-46fc-a9a2-7a6e82e5719f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538461</th>\n",
       "      <td>I wasn't going to do this, but I ...</td>\n",
       "      <td>i wasn t going to do this but i have no choic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340758</th>\n",
       "      <td>Im looking at this fine dir...</td>\n",
       "      <td>im looking at this fine director and thinking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445747</th>\n",
       "      <td>Well, this was rather surprising. I we...</td>\n",
       "      <td>well this was rather surprising i went to pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652503</th>\n",
       "      <td>It was the last one. We picked it up n ...</td>\n",
       "      <td>it was the last one we picked it up n started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568568</th>\n",
       "      <td>now for a random thoughtful excerpt...</td>\n",
       "      <td>now for a random thoughtful excerpt from a ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371507</th>\n",
       "      <td>I totally forgot that I had won (again)...</td>\n",
       "      <td>i totally forgot that i had won again two tic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157822</th>\n",
       "      <td>&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp...</td>\n",
       "      <td>nbsp nbsp nbsp nbsp nbsp i ask that you all b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53976</th>\n",
       "      <td>Today Marie called and said that ...</td>\n",
       "      <td>today marie called and said that her relation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303516</th>\n",
       "      <td>Just for all of you wondering, the old ...</td>\n",
       "      <td>just for all of you wondering the old amy luh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258329</th>\n",
       "      <td>yay im really happy rite now. For chris...</td>\n",
       "      <td>yay im really happy rite now for christmas se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92694</th>\n",
       "      <td>I am now the proud owner of Big Fish, w...</td>\n",
       "      <td>i am now the proud owner of big fish well a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433407</th>\n",
       "      <td>I bought a new CD today! :D This on...</td>\n",
       "      <td>i bought a new cd today d this one definitely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182139</th>\n",
       "      <td>It's Debbie's birthday today. Just sen...</td>\n",
       "      <td>it s debbie s birthday today just sent her an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469799</th>\n",
       "      <td>hallo from gw. back in d.c. :)</td>\n",
       "      <td>hallo from gw back in d c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557677</th>\n",
       "      <td>The last thing that this movie is going...</td>\n",
       "      <td>the last thing that this movie is going to ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357219</th>\n",
       "      <td>.     Well..I finally got the title...</td>\n",
       "      <td>well i finally got the title to the car i bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50085</th>\n",
       "      <td>urlLink    My cousin Andy and Grandma ...</td>\n",
       "      <td>urllink my cousin andy and grandma marjorie m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616996</th>\n",
       "      <td>But I'd miss novels, alcohol, nicotine,...</td>\n",
       "      <td>but i d miss novels alcohol nicotine swearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362231</th>\n",
       "      <td>The bluest skies you’ve ever seen...</td>\n",
       "      <td>the bluest skies you ve ever seen are in seat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414846</th>\n",
       "      <td>urlLink More Pictures  -- from bef...</td>\n",
       "      <td>urllink more pictures from before may th so t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108572</th>\n",
       "      <td>I'm December too: Loyal and generou...</td>\n",
       "      <td>i m december too loyal and generous i like to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238524</th>\n",
       "      <td>Personal Ad   'SINGLE BLACK FEMA...</td>\n",
       "      <td>personal ad single black female seeks male co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306514</th>\n",
       "      <td>haix.. reallie si be...</td>\n",
       "      <td>haix reallie si bei sianx lehx sian until now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497631</th>\n",
       "      <td>ok, so i visited a blog called bigwhite...</td>\n",
       "      <td>ok so i visited a blog called bigwhiteguy com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469308</th>\n",
       "      <td>(yeah, i cheated and checked at webster...</td>\n",
       "      <td>yeah i cheated and checked at webster com fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269088</th>\n",
       "      <td>urlLink Mac OS X 10.3 Panther (11/...</td>\n",
       "      <td>urllink mac os x panther arstechnica has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78447</th>\n",
       "      <td>urlLink    goofing off at lunch&amp;nbsp; ...</td>\n",
       "      <td>urllink goofing off at lunch nbsp urllink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205970</th>\n",
       "      <td>1st official entry:  Today: At offi...</td>\n",
       "      <td>st official entry today at office working on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465466</th>\n",
       "      <td>Oi! Nutters!  Today was kinda fun and k...</td>\n",
       "      <td>oi nutters today was kinda fun and kinda sad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441430</th>\n",
       "      <td>&amp;nbsp; breaky - half bowl of ...</td>\n",
       "      <td>nbsp breaky half bowl of coco pops w full cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419646</th>\n",
       "      <td>Steph, I'm so sorry to hear about...</td>\n",
       "      <td>steph i m so sorry to hear about your uncle i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227517</th>\n",
       "      <td>This weekend I will be at  urlLink ...</td>\n",
       "      <td>this weekend i will be at urllink kraftwerk y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410323</th>\n",
       "      <td>Happy Birthday Nutter Butter!...</td>\n",
       "      <td>happy birthday nutter butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502785</th>\n",
       "      <td>Batacumbele - Yoruba language meaning ...</td>\n",
       "      <td>batacumbele yoruba language meaning to kneel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220667</th>\n",
       "      <td>CAPTAIN Jack Sparrow: Very Interesting....</td>\n",
       "      <td>captain jack sparrow very interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>right now, i have on no shoes.  no ...</td>\n",
       "      <td>right now i have on no shoes no shirt and yet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189239</th>\n",
       "      <td>Special thanks go out to  urlLink Brent...</td>\n",
       "      <td>special thanks go out to urllink brent for ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111732</th>\n",
       "      <td>HOLLA 1983...I think it's year of the d...</td>\n",
       "      <td>holla i think it s year of the dog ruff i thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70625</th>\n",
       "      <td>its the only way to eat it. yum. left o...</td>\n",
       "      <td>its the only way to eat it yum left over nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673603</th>\n",
       "      <td>Stewart,},  -- abolition,i must counter...</td>\n",
       "      <td>stewart abolition i must counter abolition i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297213</th>\n",
       "      <td>Hmmm....,           Intizaar is bac...</td>\n",
       "      <td>hmmm intizaar is back people well i m going f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366161</th>\n",
       "      <td>Amanda is one of the few chick...</td>\n",
       "      <td>amanda is one of the few chick rockers that i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503367</th>\n",
       "      <td>It's the worst feeling in the world...</td>\n",
       "      <td>it s the worst feeling in the world the one t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103027</th>\n",
       "      <td>posted by Bruce Baugh                   ...</td>\n",
       "      <td>posted by bruce baugh urllink drive thru rpg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54802</th>\n",
       "      <td>I AM sOOOOOO Freaking PISSED!...</td>\n",
       "      <td>i am soooooo freaking pissed my mom and step ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529984</th>\n",
       "      <td>My life is so screwed up right now. My ...</td>\n",
       "      <td>my life is so screwed up right now my emotion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196162</th>\n",
       "      <td>Wow! That's great! Both The Mac Shac &amp; ...</td>\n",
       "      <td>wow that s great both the mac shac the self d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574594</th>\n",
       "      <td>Baseball is here. Too bad the Cardinals...</td>\n",
       "      <td>baseball is here too bad the cardinals weren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451262</th>\n",
       "      <td>What is life, but an accrual of experie...</td>\n",
       "      <td>what is life but an accrual of experiences yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474965</th>\n",
       "      <td>I just finished the Virgin Suicid...</td>\n",
       "      <td>i just finished the virgin suicides interesti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1250ee2e-64be-46fc-a9a2-7a6e82e5719f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1250ee2e-64be-46fc-a9a2-7a6e82e5719f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1250ee2e-64be-46fc-a9a2-7a6e82e5719f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "538461               I wasn't going to do this, but I ...   \n",
       "340758                     Im looking at this fine dir...   \n",
       "445747          Well, this was rather surprising. I we...   \n",
       "652503         It was the last one. We picked it up n ...   \n",
       "568568             now for a random thoughtful excerpt...   \n",
       "371507         I totally forgot that I had won (again)...   \n",
       "157822                   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp...   \n",
       "53976                Today Marie called and said that ...   \n",
       "303516         Just for all of you wondering, the old ...   \n",
       "258329         yay im really happy rite now. For chris...   \n",
       "92694          I am now the proud owner of Big Fish, w...   \n",
       "433407             I bought a new CD today! :D This on...   \n",
       "182139          It's Debbie's birthday today. Just sen...   \n",
       "469799           hallo from gw. back in d.c. :)             \n",
       "557677         The last thing that this movie is going...   \n",
       "357219             .     Well..I finally got the title...   \n",
       "50085           urlLink    My cousin Andy and Grandma ...   \n",
       "616996         But I'd miss novels, alcohol, nicotine,...   \n",
       "362231               The bluest skies you’ve ever seen...   \n",
       "414846              urlLink More Pictures  -- from bef...   \n",
       "108572             I'm December too: Loyal and generou...   \n",
       "238524                Personal Ad   'SINGLE BLACK FEMA...   \n",
       "306514                            haix.. reallie si be...   \n",
       "497631         ok, so i visited a blog called bigwhite...   \n",
       "469308         (yeah, i cheated and checked at webster...   \n",
       "269088              urlLink Mac OS X 10.3 Panther (11/...   \n",
       "78447           urlLink    goofing off at lunch&nbsp; ...   \n",
       "205970             1st official entry:  Today: At offi...   \n",
       "465466         Oi! Nutters!  Today was kinda fun and k...   \n",
       "441430                   &nbsp; breaky - half bowl of ...   \n",
       "419646               Steph, I'm so sorry to hear about...   \n",
       "227517             This weekend I will be at  urlLink ...   \n",
       "410323                   Happy Birthday Nutter Butter!...   \n",
       "502785          Batacumbele - Yoruba language meaning ...   \n",
       "220667         CAPTAIN Jack Sparrow: Very Interesting....   \n",
       "2885               right now, i have on no shoes.  no ...   \n",
       "189239         Special thanks go out to  urlLink Brent...   \n",
       "111732         HOLLA 1983...I think it's year of the d...   \n",
       "70625          its the only way to eat it. yum. left o...   \n",
       "673603         Stewart,},  -- abolition,i must counter...   \n",
       "297213             Hmmm....,           Intizaar is bac...   \n",
       "366161                  Amanda is one of the few chick...   \n",
       "503367             It's the worst feeling in the world...   \n",
       "103027        posted by Bruce Baugh                   ...   \n",
       "54802                    I AM sOOOOOO Freaking PISSED!...   \n",
       "529984         My life is so screwed up right now. My ...   \n",
       "196162         Wow! That's great! Both The Mac Shac & ...   \n",
       "574594         Baseball is here. Too bad the Cardinals...   \n",
       "451262         What is life, but an accrual of experie...   \n",
       "474965               I just finished the Virgin Suicid...   \n",
       "\n",
       "                                          normalized_text  \n",
       "538461   i wasn t going to do this but i have no choic...  \n",
       "340758   im looking at this fine director and thinking...  \n",
       "445747   well this was rather surprising i went to pos...  \n",
       "652503   it was the last one we picked it up n started...  \n",
       "568568   now for a random thoughtful excerpt from a ch...  \n",
       "371507   i totally forgot that i had won again two tic...  \n",
       "157822   nbsp nbsp nbsp nbsp nbsp i ask that you all b...  \n",
       "53976    today marie called and said that her relation...  \n",
       "303516   just for all of you wondering the old amy luh...  \n",
       "258329   yay im really happy rite now for christmas se...  \n",
       "92694    i am now the proud owner of big fish well a c...  \n",
       "433407   i bought a new cd today d this one definitely...  \n",
       "182139   it s debbie s birthday today just sent her an...  \n",
       "469799                         hallo from gw back in d c   \n",
       "557677   the last thing that this movie is going to ne...  \n",
       "357219   well i finally got the title to the car i bou...  \n",
       "50085    urllink my cousin andy and grandma marjorie m...  \n",
       "616996   but i d miss novels alcohol nicotine swearing...  \n",
       "362231   the bluest skies you ve ever seen are in seat...  \n",
       "414846   urllink more pictures from before may th so t...  \n",
       "108572   i m december too loyal and generous i like to...  \n",
       "238524   personal ad single black female seeks male co...  \n",
       "306514   haix reallie si bei sianx lehx sian until now...  \n",
       "497631   ok so i visited a blog called bigwhiteguy com...  \n",
       "469308   yeah i cheated and checked at webster com fir...  \n",
       "269088   urllink mac os x panther arstechnica has been...  \n",
       "78447          urllink goofing off at lunch nbsp urllink   \n",
       "205970   st official entry today at office working on ...  \n",
       "465466   oi nutters today was kinda fun and kinda sad ...  \n",
       "441430   nbsp breaky half bowl of coco pops w full cre...  \n",
       "419646   steph i m so sorry to hear about your uncle i...  \n",
       "227517   this weekend i will be at urllink kraftwerk y...  \n",
       "410323                      happy birthday nutter butter   \n",
       "502785   batacumbele yoruba language meaning to kneel ...  \n",
       "220667             captain jack sparrow very interesting   \n",
       "2885     right now i have on no shoes no shirt and yet...  \n",
       "189239   special thanks go out to urllink brent for ho...  \n",
       "111732   holla i think it s year of the dog ruff i thi...  \n",
       "70625    its the only way to eat it yum left over nice...  \n",
       "673603   stewart abolition i must counter abolition i ...  \n",
       "297213   hmmm intizaar is back people well i m going f...  \n",
       "366161   amanda is one of the few chick rockers that i...  \n",
       "503367   it s the worst feeling in the world the one t...  \n",
       "103027   posted by bruce baugh urllink drive thru rpg ...  \n",
       "54802    i am soooooo freaking pissed my mom and step ...  \n",
       "529984   my life is so screwed up right now my emotion...  \n",
       "196162   wow that s great both the mac shac the self d...  \n",
       "574594   baseball is here too bad the cardinals weren ...  \n",
       "451262   what is life but an accrual of experiences yo...  \n",
       "474965   i just finished the virgin suicides interesti...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "blogs_sample_df['normalized_text'] = blogs_sample_df['normalized_text'].apply(normalize_lower_case)\n",
    "blogs_sample_df.loc[:, ['text', 'normalized_text']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-S5pB6ZG4lpU"
   },
   "outputs": [],
   "source": [
    "#C.Remove all Stopwords [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3MeRhxzkrsq2"
   },
   "outputs": [],
   "source": [
    "def stopword_lemma(text):\n",
    "    token = nltk.word_tokenize(text)\n",
    "    text_stop = [x for x in token if x not in set(stopwords.words('english'))]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text_lemma = [lemmatizer.lemmatize(word) for word in text_stop]\n",
    "    text_lemma = ' '.join(text_lemma)\n",
    "    return text_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "zE1C1Ancu1Ou"
   },
   "outputs": [],
   "source": [
    "def normalize_remove_stop_words(text: str) -> str:\n",
    "    text = stopword_lemma(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "R_AQEXsbvETo",
    "outputId": "a91ee4e2-f398-4e34-cf99-0b4f8dde0f4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5f2492e4-fd8f-45bc-946f-414cbb390b28\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538461</th>\n",
       "      <td>I wasn't going to do this, but I ...</td>\n",
       "      <td>going choice comment fact producer contracted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340758</th>\n",
       "      <td>Im looking at this fine dir...</td>\n",
       "      <td>im looking fine director thinking may end list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445747</th>\n",
       "      <td>Well, this was rather surprising. I we...</td>\n",
       "      <td>well rather surprising went post comment urlli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652503</th>\n",
       "      <td>It was the last one. We picked it up n ...</td>\n",
       "      <td>last one picked n started fighting moment enth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568568</th>\n",
       "      <td>now for a random thoughtful excerpt...</td>\n",
       "      <td>random thoughtful excerpt chat finalsaturnian ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f2492e4-fd8f-45bc-946f-414cbb390b28')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5f2492e4-fd8f-45bc-946f-414cbb390b28 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5f2492e4-fd8f-45bc-946f-414cbb390b28');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "538461               I wasn't going to do this, but I ...   \n",
       "340758                     Im looking at this fine dir...   \n",
       "445747          Well, this was rather surprising. I we...   \n",
       "652503         It was the last one. We picked it up n ...   \n",
       "568568             now for a random thoughtful excerpt...   \n",
       "\n",
       "                                          normalized_text  \n",
       "538461  going choice comment fact producer contracted ...  \n",
       "340758  im looking fine director thinking may end list...  \n",
       "445747  well rather surprising went post comment urlli...  \n",
       "652503  last one picked n started fighting moment enth...  \n",
       "568568  random thoughtful excerpt chat finalsaturnian ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_sample_df['normalized_text'] = blogs_sample_df['normalized_text'].apply(normalize_remove_stop_words)\n",
    "blogs_sample_df.loc[:, ['text', 'normalized_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqYLeg1yrrQQ"
   },
   "outputs": [],
   "source": [
    "#D.Remove all extra white spaces [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "PcrV0KTK6cQy"
   },
   "outputs": [],
   "source": [
    "\n",
    "blogs_sample_df.normalized_text = blogs_sample_df.normalized_text.replace('\\s+', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "B5ar5yH02Ndo"
   },
   "outputs": [],
   "source": [
    "def remove_whitespace(x):\n",
    "    \"\"\"\n",
    "    Helper function to remove any blank space from a string\n",
    "    x: a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove spaces inside of the string\n",
    "        x = \" \".join(x.split())\n",
    "        x.replace(\" \",\"\")\n",
    "        x.strip()\n",
    "        x.lstrip()\n",
    "        x.rstrip()\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "gWnapaDV2TdI"
   },
   "outputs": [],
   "source": [
    "\n",
    "blogs_sample_df.normalized_text = blogs_sample_df.normalized_text.apply(remove_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "Ud7ECjF91pZA",
    "outputId": "11eabd9e-3ca6-41b3-e95e-fdfd21afe36c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-29a5f113-df8b-4e1a-9d11-a81971c9dab5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538461</th>\n",
       "      <td>I wasn't going to do this, but I ...</td>\n",
       "      <td>going choice comment fact producer contracted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340758</th>\n",
       "      <td>Im looking at this fine dir...</td>\n",
       "      <td>im looking fine director thinking may end list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445747</th>\n",
       "      <td>Well, this was rather surprising. I we...</td>\n",
       "      <td>well rather surprising went post comment urlli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652503</th>\n",
       "      <td>It was the last one. We picked it up n ...</td>\n",
       "      <td>last one picked n started fighting moment enth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568568</th>\n",
       "      <td>now for a random thoughtful excerpt...</td>\n",
       "      <td>random thoughtful excerpt chat finalsaturnian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371507</th>\n",
       "      <td>I totally forgot that I had won (again)...</td>\n",
       "      <td>totally forgot two ticket premiere honey starr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157822</th>\n",
       "      <td>&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp...</td>\n",
       "      <td>nbsp nbsp nbsp nbsp nbsp ask prayer family nbs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53976</th>\n",
       "      <td>Today Marie called and said that ...</td>\n",
       "      <td>today marie called said relationship screwed r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303516</th>\n",
       "      <td>Just for all of you wondering, the old ...</td>\n",
       "      <td>wondering old amy luhnette back alive well cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258329</th>\n",
       "      <td>yay im really happy rite now. For chris...</td>\n",
       "      <td>yay im really happy rite christmas seema gave ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29a5f113-df8b-4e1a-9d11-a81971c9dab5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-29a5f113-df8b-4e1a-9d11-a81971c9dab5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-29a5f113-df8b-4e1a-9d11-a81971c9dab5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "538461               I wasn't going to do this, but I ...   \n",
       "340758                     Im looking at this fine dir...   \n",
       "445747          Well, this was rather surprising. I we...   \n",
       "652503         It was the last one. We picked it up n ...   \n",
       "568568             now for a random thoughtful excerpt...   \n",
       "371507         I totally forgot that I had won (again)...   \n",
       "157822                   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp...   \n",
       "53976                Today Marie called and said that ...   \n",
       "303516         Just for all of you wondering, the old ...   \n",
       "258329         yay im really happy rite now. For chris...   \n",
       "\n",
       "                                          normalized_text  \n",
       "538461  going choice comment fact producer contracted ...  \n",
       "340758  im looking fine director thinking may end list...  \n",
       "445747  well rather surprising went post comment urlli...  \n",
       "652503  last one picked n started fighting moment enth...  \n",
       "568568  random thoughtful excerpt chat finalsaturnian ...  \n",
       "371507  totally forgot two ticket premiere honey starr...  \n",
       "157822  nbsp nbsp nbsp nbsp nbsp ask prayer family nbs...  \n",
       "53976   today marie called said relationship screwed r...  \n",
       "303516  wondering old amy luhnette back alive well cas...  \n",
       "258329  yay im really happy rite christmas seema gave ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_sample_df.loc[:, ['text', 'normalized_text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4b8DnDp4vCr"
   },
   "outputs": [],
   "source": [
    "##3. Build a base Classification model [8 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKyNaXoJ47Rg"
   },
   "outputs": [],
   "source": [
    "#A.Create dependent and independent variables [2 Marks]Hint: Treat ‘topic’ as a Target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hPseZ-fu4M9q",
    "outputId": "0b4d907e-6a91-4ccf-c433-447b0e070305"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a3de7378-761c-4fbd-8683-83ebc4ac6831\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538461</th>\n",
       "      <td>1507424</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>24,May,2003</td>\n",
       "      <td>I wasn't going to do this, but I ...</td>\n",
       "      <td>going choice comment fact producer contracted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340758</th>\n",
       "      <td>4039098</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>12,August,2004</td>\n",
       "      <td>Im looking at this fine dir...</td>\n",
       "      <td>im looking fine director thinking may end list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445747</th>\n",
       "      <td>3320360</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>Capricorn</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>Well, this was rather surprising. I we...</td>\n",
       "      <td>well rather surprising went post comment urlli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652503</th>\n",
       "      <td>3150267</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>Libra</td>\n",
       "      <td>27,May,2004</td>\n",
       "      <td>It was the last one. We picked it up n ...</td>\n",
       "      <td>last one picked n started fighting moment enth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568568</th>\n",
       "      <td>1929559</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>15,September,2003</td>\n",
       "      <td>now for a random thoughtful excerpt...</td>\n",
       "      <td>random thoughtful excerpt chat finalsaturnian ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3de7378-761c-4fbd-8683-83ebc4ac6831')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a3de7378-761c-4fbd-8683-83ebc4ac6831 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a3de7378-761c-4fbd-8683-83ebc4ac6831');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             id  gender  age  topic         sign               date  \\\n",
       "538461  1507424    male   35      4       Cancer        24,May,2003   \n",
       "340758  4039098  female   24     39  Sagittarius     12,August,2004   \n",
       "445747  3320360    male   27      4    Capricorn        12,May,2004   \n",
       "652503  3150267  female   16     34        Libra        27,May,2004   \n",
       "568568  1929559  female   16     39       Gemini  15,September,2003   \n",
       "\n",
       "                                                     text  \\\n",
       "538461               I wasn't going to do this, but I ...   \n",
       "340758                     Im looking at this fine dir...   \n",
       "445747          Well, this was rather surprising. I we...   \n",
       "652503         It was the last one. We picked it up n ...   \n",
       "568568             now for a random thoughtful excerpt...   \n",
       "\n",
       "                                          normalized_text  \n",
       "538461  going choice comment fact producer contracted ...  \n",
       "340758  im looking fine director thinking may end list...  \n",
       "445747  well rather surprising went post comment urlli...  \n",
       "652503  last one picked n started fighting moment enth...  \n",
       "568568  random thoughtful excerpt chat finalsaturnian ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "blogs_sample_df['topic'] = le.fit_transform(blogs_sample_df['topic'])\n",
    "blogs_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5tkLK6Clj0I",
    "outputId": "3644ef08-444e-4be8-950a-1d4b1c7b1824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  int64\n",
       "gender             object\n",
       "age                 int64\n",
       "topic               int64\n",
       "sign               object\n",
       "date               object\n",
       "text               object\n",
       "normalized_text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "KnirfPaGVgwW",
    "outputId": "c0668ef4-891d-4feb-d736-6c4903824fe8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ebf66fb6-7666-450b-adb9-8d4e71e01946\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538461</th>\n",
       "      <td>1507424</td>\n",
       "      <td>4</td>\n",
       "      <td>I wasn't going to do this, but I ...</td>\n",
       "      <td>going choice comment fact producer contracted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340758</th>\n",
       "      <td>4039098</td>\n",
       "      <td>39</td>\n",
       "      <td>Im looking at this fine dir...</td>\n",
       "      <td>im looking fine director thinking may end list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445747</th>\n",
       "      <td>3320360</td>\n",
       "      <td>4</td>\n",
       "      <td>Well, this was rather surprising. I we...</td>\n",
       "      <td>well rather surprising went post comment urlli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652503</th>\n",
       "      <td>3150267</td>\n",
       "      <td>34</td>\n",
       "      <td>It was the last one. We picked it up n ...</td>\n",
       "      <td>last one picked n started fighting moment enth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568568</th>\n",
       "      <td>1929559</td>\n",
       "      <td>39</td>\n",
       "      <td>now for a random thoughtful excerpt...</td>\n",
       "      <td>random thoughtful excerpt chat finalsaturnian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195958</th>\n",
       "      <td>823780</td>\n",
       "      <td>13</td>\n",
       "      <td>Another bored, bored day. Surfing, n200...</td>\n",
       "      <td>another bored bored day surfing n pre demo dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410266</th>\n",
       "      <td>2950525</td>\n",
       "      <td>6</td>\n",
       "      <td>February 17th, 2004   Leo  (...</td>\n",
       "      <td>february th leo july aug take charge today suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464929</th>\n",
       "      <td>1284157</td>\n",
       "      <td>34</td>\n",
       "      <td>Women fascinate me   Just so...</td>\n",
       "      <td>woman fascinate know squirrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168485</th>\n",
       "      <td>3871907</td>\n",
       "      <td>21</td>\n",
       "      <td>Colleges in Indiana -- and elsewhere --...</td>\n",
       "      <td>college indiana elsewhere considering whether ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147967</th>\n",
       "      <td>1476840</td>\n",
       "      <td>27</td>\n",
       "      <td>Nemesis    urlLink   ?? Which ...</td>\n",
       "      <td>nemesis urllink greek god brought urllink quiz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13007 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebf66fb6-7666-450b-adb9-8d4e71e01946')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ebf66fb6-7666-450b-adb9-8d4e71e01946 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ebf66fb6-7666-450b-adb9-8d4e71e01946');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             id  topic                                               text  \\\n",
       "538461  1507424      4               I wasn't going to do this, but I ...   \n",
       "340758  4039098     39                     Im looking at this fine dir...   \n",
       "445747  3320360      4          Well, this was rather surprising. I we...   \n",
       "652503  3150267     34         It was the last one. We picked it up n ...   \n",
       "568568  1929559     39             now for a random thoughtful excerpt...   \n",
       "...         ...    ...                                                ...   \n",
       "195958   823780     13         Another bored, bored day. Surfing, n200...   \n",
       "410266  2950525      6                    February 17th, 2004   Leo  (...   \n",
       "464929  1284157     34                    Women fascinate me   Just so...   \n",
       "168485  3871907     21         Colleges in Indiana -- and elsewhere --...   \n",
       "147967  1476840     27                  Nemesis    urlLink   ?? Which ...   \n",
       "\n",
       "                                          normalized_text  \n",
       "538461  going choice comment fact producer contracted ...  \n",
       "340758  im looking fine director thinking may end list...  \n",
       "445747  well rather surprising went post comment urlli...  \n",
       "652503  last one picked n started fighting moment enth...  \n",
       "568568  random thoughtful excerpt chat finalsaturnian ...  \n",
       "...                                                   ...  \n",
       "195958  another bored bored day surfing n pre demo dem...  \n",
       "410266  february th leo july aug take charge today suc...  \n",
       "464929                      woman fascinate know squirrel  \n",
       "168485  college indiana elsewhere considering whether ...  \n",
       "147967  nemesis urllink greek god brought urllink quiz...  \n",
       "\n",
       "[13007 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove two columns name is age,gender and date\n",
    "blogs_sample_df.drop(['age','gender', 'sign','date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTqaMUIQVWEx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "at1myT6A5A4Z"
   },
   "outputs": [],
   "source": [
    "#C.Vectorize data using any one vectorizer. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBS1VyVE7GJT",
    "outputId": "f1207976-5014-4424-cd07-fc64d8f0b831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13007, 63001)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(stop_words = set(nltk.corpus.stopwords.words('english')))\n",
    "tfidf_method = vectorizer_tfidf.fit_transform(blogs_sample_df.normalized_text)\n",
    "tfidf_method.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtkOHP7O9uus",
    "outputId": "8ca81034-1020-4a79-cf60-cdcf1054265f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create Data Frame of tdidf scores\n",
    "tfidf_df_method = pd.DataFrame(tfidf_method.toarray(),\n",
    "             columns = vectorizer_tfidf.get_feature_names(),\n",
    "             index = blogs_sample_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TWOtRsl95Nd",
    "outputId": "4eafbeef-ff3a-457b-e089-c7ef7a8f4750"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urllink    0.033293\n",
       "nbsp       0.026003\n",
       "like       0.023016\n",
       "one        0.020369\n",
       "get        0.018835\n",
       "know       0.018612\n",
       "time       0.018479\n",
       "day        0.017161\n",
       "go         0.016329\n",
       "really     0.016250\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate tfidf for all columns and list top 10\n",
    "tfidf_df_method.mean().sort_values(ascending = False).head(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_fUO5Vq64-X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYW2MYdo49sU"
   },
   "outputs": [],
   "source": [
    "#B.Split data into train and test. [1 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNZtKCr0AOcj",
    "outputId": "67ea8d01-c76b-4864-ca68-dee1f01a7f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training utterances: 11055\n",
      "Validation utterances: 1952\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(blogs_sample_df['normalized_text'].values, blogs_sample_df['topic'].values, test_size=0.15, random_state=42)\n",
    "print('Training utterances: {}'.format(X_train.shape[0]))\n",
    "print('Validation utterances: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rX0kKz5B3nW",
    "outputId": "22c66c43-900a-4d2f-97ad-e7373ae82fd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U67_Z8JzCeHW",
    "outputId": "b47ef218-032a-4275-b272-4c76acdf297a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<11055x57206 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 838454 stored elements in Compressed Sparse Row format>,\n",
       " <1952x57206 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 144941 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mm1XtwvTCqrY",
    "outputId": "13244513-f469-41fb-9271-05594e445033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<11055x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 37182 stored elements in Compressed Sparse Row format>,\n",
       " <1952x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 6181 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting  the k-best features\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "ch2 = SelectKBest(chi2, k=5000)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)\n",
    "\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "oGFYy0VQ5DJX"
   },
   "outputs": [],
   "source": [
    "#D.Build a base model for Supervised Learning - Classification. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBpAzhYYCGUv",
    "outputId": "f9964e61-9352-4716-f321-45c69086429b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy = 0.35348360655737704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "mnb_model1 = MultinomialNB()\n",
    "mnb_model1.fit(X_train, y_train)\n",
    "pred = mnb_model1.predict(X_test)\n",
    "print(\"MultinomialNB Accuracy =\",accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoZLm8235GHU"
   },
   "outputs": [],
   "source": [
    "#E.Clearly print Performance Metrics. [1 Marks]Hint: Accuracy, Precision, Recall, ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ulz1GlJA6dVo",
    "outputId": "399453a6-d991-4e51-beb1-78b19f7090f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        87\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00        10\n",
      "           7       0.00      0.00      0.00        11\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.00      0.00      0.00        12\n",
      "          10       0.00      0.00      0.00        75\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00        15\n",
      "          13       0.00      0.00      0.00        89\n",
      "          14       0.00      0.00      0.00        36\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00        16\n",
      "          17       0.00      0.00      0.00        18\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00        28\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        14\n",
      "          26       0.00      0.00      0.00        10\n",
      "          27       0.00      0.00      0.00         9\n",
      "          28       0.00      0.00      0.00        50\n",
      "          29       0.00      0.00      0.00        18\n",
      "          30       0.00      0.00      0.00        10\n",
      "          31       0.00      0.00      0.00        21\n",
      "          32       0.00      0.00      0.00        16\n",
      "          33       0.00      0.00      0.00        11\n",
      "          34       1.00      0.00      0.00       451\n",
      "          35       0.00      0.00      0.00       114\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.35      1.00      0.52       689\n",
      "\n",
      "    accuracy                           0.35      1952\n",
      "   macro avg       0.03      0.03      0.01      1952\n",
      "weighted avg       0.36      0.35      0.19      1952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuvKydxHE5ez",
    "outputId": "c885ffd5-ee3e-4a92-c96a-d3a7e1d2fbba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations:\n",
      "Since the same size is small and distributed among 39 different topics, precision and accuracy is zero for small sample sized topics. \n",
      "The model is able to predict with better precision and recall the topics with more representative data in sample.\n"
     ]
    }
   ],
   "source": [
    "print(\"Observations:\")\n",
    "print(\"Since the same size is small and distributed among 39 different topics, precision and accuracy is zero for small sample sized topics. \")\n",
    "print(\"The model is able to predict with better precision and recall the topics with more representative data in sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR1S-yvt5OLr"
   },
   "outputs": [],
   "source": [
    "##4.Improve Performance of model. [14 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqHngr6l58Ts"
   },
   "outputs": [],
   "source": [
    "#A.Experiment with other vectorisers. [4 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Xap3Bq_9E24L"
   },
   "outputs": [],
   "source": [
    "# Importing the glove model and creating the embeddings\n",
    "\n",
    "import os\n",
    "glove_path = '/content/drive/My Drive/Colab Notebooks/glove.6B.300d.txt'\n",
    "embeddings_index = {}\n",
    "f = open(glove_path, encoding='utf8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    #print(embeddings_index)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqHai9fOzxHV",
    "outputId": "6715e845-e249-457a-852d-cdd6e2048e0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking average of all word embeddings in a sentence to generate the sentence representation.\n",
    "data_list = list()\n",
    "for comp in blogs_sample_df['normalized_text']:\n",
    "    sentence = np.zeros(300)\n",
    "    count = 0\n",
    "    for w in normalize_text(comp):\n",
    "        try:\n",
    "            sentence += embeddings_index[w]\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    data_list.append(sentence / count)\n",
    "\n",
    "len(data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "X2nIQodihNmz"
   },
   "outputs": [],
   "source": [
    "blogs_sample_df[:] = np.nan_to_num(blogs_sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "606QouRi41tE",
    "outputId": "e6db4a57-43a9-4da8-f985-96d76361b0ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11055, 300) (11055,)\n"
     ]
    }
   ],
   "source": [
    "## Train_Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data_list), blogs_sample_df.topic.values, test_size=0.15, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "X_train = np.nan_to_num(X_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6yYkWQ26Bbu"
   },
   "outputs": [],
   "source": [
    "#B.Build classifier Models using other algorithms than base model. [4 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhaC51Ca43Po",
    "outputId": "3b2a5381-92f2-40f1-86e3-84b9b99b197f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB accuracy = 0.017930327868852458\n"
     ]
    }
   ],
   "source": [
    "### Training and Testing the GaussianNB classifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "gnb_model1 = GaussianNB()\n",
    "gnb_model1.fit(X_train, y_train)\n",
    "pred_gnb = gnb_model1.predict(X_test)\n",
    "print(\"GaussianNB accuracy =\",accuracy_score(y_test, pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uG2UZa5Y5Wtb",
    "outputId": "b4bb10cc-f13a-421b-e5b3-f1a6056091f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy = 0.32223360655737704\n"
     ]
    }
   ],
   "source": [
    "### Training and Testing the BernoulliNB classifier \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "bnb_model1 = BernoulliNB()\n",
    "bnb_model1.fit(X_train, y_train)\n",
    "pred_bnb = bnb_model1.predict(X_test)\n",
    "print(\"BernoulliNB accuracy =\",accuracy_score(y_test, pred_bnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBfoIOh8c9C9",
    "outputId": "d9a6ea22-14a1-42b5-f4d2-4fe4e0c9327b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy = 0.34989754098360654\n"
     ]
    }
   ],
   "source": [
    "### Training and Testing the LogisticRegression classifier \n",
    "#Changing the solver method to tune the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg2 = LogisticRegression(solver='newton-cg', random_state=1,max_iter=1000)\n",
    "\n",
    "logreg2.fit(X_train, y_train)\n",
    "pred_logreg2 = logreg2.predict(X_test)\n",
    "model_score = logreg2.score(X_test, y_test)\n",
    "print(\"LogisticRegression accuracy =\",model_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBi2Jgcm4-ih",
    "outputId": "4bf3c43f-2e9c-4afb-8f4e-41c4415aa9a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_Accuracy_Score = 0.3452868852459016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training and Testing the classifier\n",
    "## RandomForest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_gloveembed_rf=RandomForestClassifier()\n",
    "model_gloveembed_rf.fit(X_train, y_train)\n",
    "pred = model_gloveembed_rf.predict(X_test)\n",
    "print('RF_Accuracy_Score =', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xr7RE2AjyTS-",
    "outputId": "b7f44b6b-ecaf-4e90-9937-7c7d0eab20e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy = 0.35297131147540983\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Building a Support Vector Machine on train data with kernel =\"rbf\"\n",
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "prediction_svc = svc_model.predict(X_test)\n",
    "\n",
    "print('SVC accuracy =',svc_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftLuq4qlqsv5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5VTBexn6D5f"
   },
   "outputs": [],
   "source": [
    "#C.Tune Parameters/Hyperparameters of the model/s. [4 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFEwhow7VA8P",
    "outputId": "921aad9d-8221-4260-e03b-a5214d0ffa94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy Score = 0.3452868852459016\n"
     ]
    }
   ],
   "source": [
    "#tuning with max_depth,max_features of RandomForestClassifier\n",
    "## RandomForest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_gloveembed_rf_t=RandomForestClassifier(max_depth=4,max_features=4)\n",
    "model_gloveembed_rf_t.fit(X_train, y_train)\n",
    "pred_rf_t = model_gloveembed_rf.predict(X_test)\n",
    "print('RF accuracy Score =', accuracy_score(y_test, pred_rf_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1yHtoBIeAoo",
    "outputId": "3463c848-6547-42d3-dcc5-64c8537636b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy = 0.34989754098360654\n"
     ]
    }
   ],
   "source": [
    "#Changing the solver method to tune the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg2_t = LogisticRegression(solver='saga', random_state=1,max_iter=1000)\n",
    "\n",
    "logreg2_t.fit(X_train, y_train)\n",
    "pred_logreg2 = logreg2_t.predict(X_test)\n",
    "model_score = logreg2_t.score(X_test, y_test)\n",
    "print('LogisticRegression accuracy =',model_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3aJVPSB5wZR",
    "outputId": "a1aa62e8-1d03-4fbc-e72a-5421f6862e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy = 0.35297131147540983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Building a Support Vector Machine on train data with kernel =\"linear\"\n",
    "svc_model_t = SVC(kernel='linear')\n",
    "svc_model_t.fit(X_train, y_train)\n",
    "prediction_svc_t = svc_model_t.predict(X_test)\n",
    "\n",
    "print('SVC accuracy =',svc_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDnkK0JJhJX8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aevEEHxZ6GLr"
   },
   "outputs": [],
   "source": [
    "#D.Clearly print Performance Metrics. [2 Marks]Hint: Accuracy, Precision, Recall, ROC-AUC©Great Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBs-6p-66eg9",
    "outputId": "795c3887-d51f-47e5-eae5-4357ac2d61dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Logistic Regression Model : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        87\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00        10\n",
      "           7       0.00      0.00      0.00        11\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.00      0.00      0.00        12\n",
      "          10       0.00      0.00      0.00        75\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00        15\n",
      "          13       0.00      0.00      0.00        89\n",
      "          14       0.00      0.00      0.00        36\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00        16\n",
      "          17       0.00      0.00      0.00        18\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00        28\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        14\n",
      "          26       0.00      0.00      0.00        10\n",
      "          27       0.00      0.00      0.00         9\n",
      "          28       0.00      0.00      0.00        50\n",
      "          29       0.00      0.00      0.00        18\n",
      "          30       0.00      0.00      0.00        10\n",
      "          31       0.00      0.00      0.00        21\n",
      "          32       0.00      0.00      0.00        16\n",
      "          33       0.00      0.00      0.00        11\n",
      "          34       0.30      0.03      0.05       451\n",
      "          35       0.00      0.00      0.00       114\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.35      0.97      0.52       689\n",
      "\n",
      "    accuracy                           0.35      1952\n",
      "   macro avg       0.02      0.03      0.01      1952\n",
      "weighted avg       0.19      0.35      0.19      1952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for Logistic Regression Model : \")\n",
    "print(classification_report(y_test, pred_logreg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27oOi0vk3RJ9",
    "outputId": "5025259c-b3d2-4c6e-cd20-2ec152712349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low precision and recall for most of the topics is due to small representative data in the sample.\n"
     ]
    }
   ],
   "source": [
    "print(\"Low precision and recall for most of the topics is due to small representative data in the sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oX2e2uZabeZY",
    "outputId": "3fdbb1f3-02e9-4e1e-9afb-94cce2375b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Randomforest classifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        87\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00        10\n",
      "           7       0.00      0.00      0.00        11\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.00      0.00      0.00        12\n",
      "          10       1.00      0.01      0.03        75\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00        15\n",
      "          13       0.00      0.00      0.00        89\n",
      "          14       0.00      0.00      0.00        36\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00        16\n",
      "          17       0.00      0.00      0.00        18\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.50      0.02      0.04        47\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00        28\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        14\n",
      "          26       0.00      0.00      0.00        10\n",
      "          27       0.00      0.00      0.00         9\n",
      "          28       0.00      0.00      0.00        50\n",
      "          29       0.00      0.00      0.00        18\n",
      "          30       0.00      0.00      0.00        10\n",
      "          31       0.00      0.00      0.00        21\n",
      "          32       0.00      0.00      0.00        16\n",
      "          33       0.00      0.00      0.00        11\n",
      "          34       0.29      0.18      0.22       451\n",
      "          35       0.00      0.00      0.00       114\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.35      0.86      0.50       689\n",
      "\n",
      "    accuracy                           0.35      1952\n",
      "   macro avg       0.05      0.03      0.02      1952\n",
      "weighted avg       0.24      0.35      0.23      1952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for Randomforest classifier : \")\n",
    "print(classification_report(y_test, pred_rf_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jCgjhOi28Kv",
    "outputId": "ea21e0f3-dab1-407f-9da9-259f00ecaf12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for SVC classifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        87\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00        10\n",
      "           7       0.00      0.00      0.00        11\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.00      0.00      0.00        12\n",
      "          10       0.00      0.00      0.00        75\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00        15\n",
      "          13       0.00      0.00      0.00        89\n",
      "          14       0.00      0.00      0.00        36\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00        16\n",
      "          17       0.00      0.00      0.00        18\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00        28\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        14\n",
      "          26       0.00      0.00      0.00        10\n",
      "          27       0.00      0.00      0.00         9\n",
      "          28       0.00      0.00      0.00        50\n",
      "          29       0.00      0.00      0.00        18\n",
      "          30       0.00      0.00      0.00        10\n",
      "          31       0.00      0.00      0.00        21\n",
      "          32       0.00      0.00      0.00        16\n",
      "          33       0.00      0.00      0.00        11\n",
      "          34       0.00      0.00      0.00       451\n",
      "          35       0.00      0.00      0.00       114\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.00      0.00      0.00         3\n",
      "          38       0.00      0.00      0.00         5\n",
      "          39       0.35      1.00      0.52       689\n",
      "\n",
      "    accuracy                           0.35      1952\n",
      "   macro avg       0.01      0.03      0.01      1952\n",
      "weighted avg       0.12      0.35      0.18      1952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for SVC classifier : \")\n",
    "print(classification_report(y_test, prediction_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YV_Od7IQ6IYx"
   },
   "outputs": [],
   "source": [
    "##5.Share insights on relative performance comparison [8 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxHPuvtK6K5x"
   },
   "outputs": [],
   "source": [
    " #A.Which vectorizer performed better? Probable reason?. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eG-BXpGMhwIR",
    "outputId": "9d551f4f-3c21-401f-920a-b72322de5717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here TfidfVectorizer based model has performed well over Glove embedding based model.\n",
      "Best results are obtained using the more generic TF-IDF method by a factor of roughly 1-2%. \n",
      "Reason being TF-IDF method gains more information from longer documents compared to the embedding method.\n"
     ]
    }
   ],
   "source": [
    "print(\"Here TfidfVectorizer based model has performed well over Glove embedding based model.\")\n",
    "print(\"Best results are obtained using the more generic TF-IDF method by a factor of roughly 1-2%. \")\n",
    "print(\"Reason being TF-IDF method gains more information from longer documents compared to the embedding method.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvSX4wsb6Mt8"
   },
   "outputs": [],
   "source": [
    " #B.Which model outperformed? Probable reason? [2 Marks]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMYasuzakzcd",
    "outputId": "412978cf-2d70-4ab2-f6d2-a528c0cdfc48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB based model has performed well based on the nature of the data.\n",
      "SVC with rbf kernel has almost same accuracy as MultinomialNB.\n",
      "The algorithm is based on the Bayes theorem and predicts the tag of a text.\n",
      "It calculates the probability of each tag for a given sample and then gives the tag with the highest probability as output.\n"
     ]
    }
   ],
   "source": [
    "print(\"MultinomialNB based model has performed well based on the nature of the data.\")\n",
    "print(\"SVC with rbf kernel has almost same accuracy as MultinomialNB.\")\n",
    "print(\"The algorithm is based on the Bayes theorem and predicts the tag of a text.\")\n",
    "print(\"It calculates the probability of each tag for a given sample and then gives the tag with the highest probability as output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "9Bzpcs_b6OhG"
   },
   "outputs": [],
   "source": [
    "#C.Which  parameter/hyperparameter  significantly  helped to improve performance?Probable reason?. [2 Marks]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDDYssbXlqZa",
    "outputId": "4611ed34-acca-4c0d-8b84-581abea7aa06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB model  as the parameter for the model, is best suited for NLP classification problem among all the Naive Bayes classifiers.\n",
      " SVC classifier can also be used for comparoitive performance.\n"
     ]
    }
   ],
   "source": [
    "print(\"MultinomialNB model  as the parameter for the model, is best suited for NLP classification problem among all the Naive Bayes classifiers.\")\n",
    "print(\" SVC classifier can also be used for comparoitive performance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQdacFLi6Sep"
   },
   "outputs": [],
   "source": [
    "#D.According  to  you,  which  performance  metric  should  be given most importance, why?. [2 Marks]     Part A - 40 Marks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4kPTS2o3D583",
    "outputId": "5e7020e3-ef4c-423f-be57-7ebf58fadb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is the important metric as we want to categorise blogs correctly. \n",
      "To handle furture request for a particular topic, the document shoud be correctly classified.\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision is the important metric as we want to categorise blogs correctly. \")\n",
    "print(\"To handle furture request for a particular topic, the document shoud be correctly classified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6NRv17KD6Hq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVWVOwA9D6SE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIo2kS7S6fpz"
   },
   "outputs": [],
   "source": [
    "##PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDA6gNe36fxm"
   },
   "outputs": [],
   "source": [
    "#PROJECT OBJECTIVE: Design a python based interactive semi - rule based chatbot which can do the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOvseV-L1EhK",
    "outputId": "3cb4aeb3-fe3f-4fd1-8a01-0ef49e9298bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tag': 'Intro', 'patterns': ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time'], 'responses': ['Hello from GreatLearning!. how can i help you ?'], 'context_set': ''}\n",
      "{'tag': 'Exit', 'patterns': ['thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'byee', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy'], 'responses': ['I hope I was able to assist you well, Good Bye'], 'context_set': ''}\n",
      "{'tag': 'Olympus', 'patterns': ['olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus'], 'responses': ['Link: Refer to Olympus wiki'], 'context_set': ''}\n",
      "{'tag': 'SL', 'patterns': ['i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techb=niques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters'], 'responses': ['Refer to Machine Learning links on wiki '], 'context_set': ''}\n",
      "{'tag': 'NN', 'patterns': ['what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'sgd'], 'responses': ['Refer Links on Neural Nets wiki'], 'context_set': ''}\n",
      "{'tag': 'Bot', 'patterns': ['what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours'], 'responses': ['I am your virtual learning assistant'], 'context_set': ''}\n",
      "{'tag': 'Profane', 'patterns': ['what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit'], 'responses': ['Please use respectful words'], 'context_set': ''}\n",
      "{'tag': 'Ticket', 'patterns': ['my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket'], 'responses': ['Tarnsferring the request to your PM'], 'context_set': ''}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('/content/drive/My Drive/Colab Notebooks/GLBotCorpus.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "corpus_data = json.load(f)\n",
    "  \n",
    "# Iterating through the json\n",
    "# list\n",
    "for i in corpus_data['intents']:\n",
    "    print(i)\n",
    "  \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrpqU7mDe2Cj"
   },
   "outputs": [],
   "source": [
    "#1. Start chat session with greetings and ask what the user is looking for. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_n9vI3vo7kdB"
   },
   "outputs": [],
   "source": [
    "#2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus. [10 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rWV5VtO7qfN"
   },
   "outputs": [],
   "source": [
    "#3. End the chat session only if the user requests to end else ask what the user is looking for. Loop continues till the user asks to end it. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Bm0EQTIFCe-R"
   },
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer() \n",
    "# lists\n",
    "ourClasses = []\n",
    "newWords = []\n",
    "doc_X = []\n",
    "doc_Y = []\n",
    "#  tokenize intents into words and the patterns and their associated tags lists\n",
    "for intent in corpus_data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        ournewTkns = nltk.word_tokenize(pattern)\n",
    "        newWords.extend(ournewTkns)\n",
    "        doc_X.append(pattern)\n",
    "        doc_Y.append(intent[\"tag\"])\n",
    "\n",
    "    # add tags to their respective classes\n",
    "    if intent[\"tag\"] not in ourClasses:\n",
    "        ourClasses.append(intent[\"tag\"])\n",
    "\n",
    "# set words to lowercase if not in punctuation\n",
    "newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] \n",
    "# sorting words\n",
    "newWords = sorted(set(newWords))\n",
    "ourClasses = sorted(set(ourClasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "SpzPqzSjCfiA"
   },
   "outputs": [],
   "source": [
    "trainingData = [] # training list array\n",
    "outEmpty = [0] * len(ourClasses)\n",
    "# bow model\n",
    "for idx, doc in enumerate(doc_X):\n",
    "    bagOfwords = []\n",
    "    text = lm.lemmatize(doc.lower())\n",
    "    for word in newWords:\n",
    "        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n",
    "\n",
    "    outputRow = list(outEmpty)\n",
    "    outputRow[ourClasses.index(doc_Y[idx])] = 1\n",
    "    trainingData.append([bagOfwords, outputRow])\n",
    "\n",
    "random.shuffle(trainingData)\n",
    "trainingData = np.array(trainingData, dtype=object)\n",
    "\n",
    "x = np.array(list(trainingData[:, 0]))\n",
    "y = np.array(list(trainingData[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "ybuYYNr6CfmI"
   },
   "outputs": [],
   "source": [
    "# defining a Neural Network classifier\n",
    "iShape = (len(x[0]),)\n",
    "oShape = len(y[0])\n",
    "# parameter definition\n",
    "bot_model = Sequential()\n",
    "\n",
    "bot_model.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n",
    "bot_model.add(Dropout(0.5))\n",
    "\n",
    "bot_model.add(Dense(64, activation=\"relu\"))\n",
    "bot_model.add(Dropout(0.3))\n",
    "bot_model.add(Dense(oShape, activation = \"softmax\"))\n",
    "\n",
    "md = tensorF.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZH1ZH5tYfYz",
    "outputId": "de74969b-8454-43cf-b2b6-5c8a02031835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               20480     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,256\n",
      "Trainable params: 29,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#compiling the model\n",
    "bot_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=md,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# model summary\n",
    "print(bot_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFYnDdt-Yptd",
    "outputId": "d393bd84-7eac-499f-df63-3ed18e12cff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 8ms/step - loss: 2.0490 - accuracy: 0.1705\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.7979 - accuracy: 0.2558\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5711 - accuracy: 0.4884\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3325 - accuracy: 0.5891\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0947 - accuracy: 0.6124\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9402 - accuracy: 0.6512\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.7984\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.8295\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8992\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8605\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2113 - accuracy: 0.9457\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8915\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9457\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9690\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9457\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9612\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9690\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9612\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9922\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9767\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9767\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9845\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9922\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9845\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9690\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9690\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9922\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9690\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9922\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9922\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9922\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9922\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9922\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9922\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9922\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9922\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9922\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9922\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9767\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9767\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9922\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9922\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9767\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9922\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0406 - accuracy: 0.9845\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9845\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9922\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.9845\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9922\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9922\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9922\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9767\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9845\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9845\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9922\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9922\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9767\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9922\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9922\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9922\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9922\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1964e-04 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0768 - accuracy: 0.9922\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9922\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9922\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9922\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9922\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9767\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9922\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1375 - accuracy: 0.9767\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9767\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9922\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9690\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9767\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9845\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9767\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9922\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9845\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9845\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9922\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9922\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9922\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9922\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9922\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9922\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9922\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9922\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9922\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9922\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9922\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9922\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9922\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9922\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9922\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1014 - accuracy: 0.9845\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9922\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9922\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9845\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9922\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.9457\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9922\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.9767\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9690\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.9612\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9845\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9767\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.9690\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9845\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2202 - accuracy: 0.9535\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9845\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1490 - accuracy: 0.9690\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9922\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9767\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9845\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9845\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9922\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.9767\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9922\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9612\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9767\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.9380\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9690\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9922\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.9690\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9767\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9845\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4bf1a41310>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "bot_model.fit(x, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Sjv1UybsCfrx"
   },
   "outputs": [],
   "source": [
    "#tokenizing entered text\n",
    "def tokenizeNewText(text):\n",
    "  new_tokns = nltk.word_tokenize(text)\n",
    "  new_tokns = [lm.lemmatize(word) for word in new_tokns]\n",
    "  return new_tokns\n",
    "\n",
    "#creating counts for words in msg\n",
    "def wordBag(msgtext, vocab):\n",
    "  new_tokens = tokenizeNewText(msgtext)\n",
    "  bagOwords = [0] * len(vocab)\n",
    "  for t in new_tokens:\n",
    "    for idx, word in enumerate(vocab):\n",
    "      if word == t:\n",
    "        bagOwords[idx] = 1\n",
    "  return np.array(bagOwords)\n",
    "\n",
    "#making predictions using the sequential model defined above.\n",
    "def bag_of_words_model(msgtext, vocab, labels):\n",
    "  newThreshold = 0.3\n",
    "  bagOwords = wordBag(msgtext, vocab)\n",
    "  result = bot_model.predict(np.array([bagOwords]))[0]\n",
    "  yp = [[idx, res] for idx, res in enumerate(result) if res > newThreshold]\n",
    "\n",
    "  yp.sort(key=lambda x: x[1], reverse=True)\n",
    "  newList = []\n",
    "  for r in yp:\n",
    "    newList.append(labels[r[0]])\n",
    "  return newList\n",
    "\n",
    "def bot_Response(firstlist, fJson):\n",
    "  tag = firstlist[0]\n",
    "  listOfIntents = fJson[\"intents\"]\n",
    "  for i in listOfIntents:\n",
    "    if i[\"tag\"] == tag:\n",
    "      result = random.choice(i[\"responses\"])\n",
    "      break\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9aJpSWJCfxM",
    "outputId": "4dbf6862-eac8-4f29-fafe-e5f5c3336647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************************\n",
      "*********************************************************************************\n",
      " Welcome!! This is GreatLearning Chatbot. Please type 'Exit' to end this session.\n",
      "hi\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Hello from GreatLearning!. how can i help you ?\n",
      "machine learning\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Refer to Machine Learning links on wiki \n",
      "Exit\n",
      "Ending the session.\n"
     ]
    }
   ],
   "source": [
    "continue_flag = True\n",
    "print(\"*********************************************************************************\")\n",
    "print(\"*********************************************************************************\")\n",
    "print(\" Welcome!! This is GreatLearning Chatbot. Please type 'Exit' to end this session.\")\n",
    "\n",
    "while (continue_flag == True):\n",
    "  newMessage = input(\"\")\n",
    "  if newMessage != 'Exit':\n",
    "      intents = bag_of_words_model(newMessage, newWords, ourClasses)\n",
    "      response = bot_Response(intents, corpus_data)\n",
    "      print(response)\n",
    "  else:\n",
    "    print(\"Ending the session.\")\n",
    "    continue_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6_cBL3PCf1T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQevPsPgCf6G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSxUAXvICf_-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuB9LwPQCgDz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhQvigslCgIR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEx1BvuZCgMj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LWD4YIRCdA9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omahWr5fCdMA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeB4CQhP_OV1"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sa7ZNaOy3Nzx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bfj8_oDM3Hud"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
