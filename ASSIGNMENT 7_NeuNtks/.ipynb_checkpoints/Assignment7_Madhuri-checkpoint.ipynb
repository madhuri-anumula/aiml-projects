{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment- Madhuri A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score, confusion_matrix\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pywrap_tensorflow' from partially initialized module 'tensorflow.python' (most likely due to a circular import) (/Users/madhuri/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1y/5w07l1hj7lj7r956thdwjdrw0000gn/T/ipykernel_9347/137459197.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pywrap_tensorflow' from partially initialized module 'tensorflow.python' (most likely due to a circular import) (/Users/madhuri/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.  Data import and Understanding [10 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A. Read the ‘Signals.csv’ as DataFrame and import required libraries. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter 1  Parameter 2  Parameter 3  Parameter 4  Parameter 5  \\\n",
       "0          7.4         0.70         0.00          1.9        0.076   \n",
       "1          7.8         0.88         0.00          2.6        0.098   \n",
       "2          7.8         0.76         0.04          2.3        0.092   \n",
       "3         11.2         0.28         0.56          1.9        0.075   \n",
       "4          7.4         0.70         0.00          1.9        0.076   \n",
       "\n",
       "   Parameter 6  Parameter 7  Parameter 8  Parameter 9  Parameter 10  \\\n",
       "0         11.0         34.0       0.9978         3.51          0.56   \n",
       "1         25.0         67.0       0.9968         3.20          0.68   \n",
       "2         15.0         54.0       0.9970         3.26          0.65   \n",
       "3         17.0         60.0       0.9980         3.16          0.58   \n",
       "4         11.0         34.0       0.9978         3.51          0.56   \n",
       "\n",
       "   Parameter 11  Signal_Strength  \n",
       "0           9.4                5  \n",
       "1           9.8                5  \n",
       "2           9.8                5  \n",
       "3           9.8                6  \n",
       "4           9.4                5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals_df  = project_path + '/content/drive/My Drive/Colab Notebooks/Signals.csv'\n",
    "print(signals_df.shape)\n",
    "signals_df.columns\n",
    "signals_df.dtypes\n",
    "signals_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter 1        float64\n",
       "Parameter 2        float64\n",
       "Parameter 3        float64\n",
       "Parameter 4        float64\n",
       "Parameter 5        float64\n",
       "Parameter 6        float64\n",
       "Parameter 7        float64\n",
       "Parameter 8        float64\n",
       "Parameter 9        float64\n",
       "Parameter 10       float64\n",
       "Parameter 11       float64\n",
       "Signal_Strength      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## B. Check for missing values and print percentage for each attribute. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter 1</th>\n",
       "      <td>Parameter 1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 2</th>\n",
       "      <td>Parameter 2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 3</th>\n",
       "      <td>Parameter 3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 4</th>\n",
       "      <td>Parameter 4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 5</th>\n",
       "      <td>Parameter 5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 6</th>\n",
       "      <td>Parameter 6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 7</th>\n",
       "      <td>Parameter 7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 8</th>\n",
       "      <td>Parameter 8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 9</th>\n",
       "      <td>Parameter 9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 10</th>\n",
       "      <td>Parameter 10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 11</th>\n",
       "      <td>Parameter 11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal_Strength</th>\n",
       "      <td>Signal_Strength</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column_name  percent_missing\n",
       "Parameter 1          Parameter 1              0.0\n",
       "Parameter 2          Parameter 2              0.0\n",
       "Parameter 3          Parameter 3              0.0\n",
       "Parameter 4          Parameter 4              0.0\n",
       "Parameter 5          Parameter 5              0.0\n",
       "Parameter 6          Parameter 6              0.0\n",
       "Parameter 7          Parameter 7              0.0\n",
       "Parameter 8          Parameter 8              0.0\n",
       "Parameter 9          Parameter 9              0.0\n",
       "Parameter 10        Parameter 10              0.0\n",
       "Parameter 11        Parameter 11              0.0\n",
       "Signal_Strength  Signal_Strength              0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_feature_missing = signals_df.isnull().sum() * 100 / len(signals_df)\n",
    "missing_data_value_df = pd.DataFrame({'column_name': signals_df.columns,\n",
    "                                 'percent_missing': percent_feature_missing})\n",
    "missing_data_value_df\n",
    "\n",
    "#print(\"No missing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## C. Check for presence of duplicate records in the dataset and impute with appropriate method. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate exists in Dataframe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "has_duplicates= signals_df.duplicated()\n",
    "\n",
    "if True in has_duplicates.values:\n",
    "    print('Duplicate exists in Dataframe')\n",
    "else:\n",
    "    print('No Duplicate exists in Dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## D. Visualise distribution of the target variable. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "ax = sns.countplot(x=\"Signal_Strength\", data=signals_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## E. Share insights from the initial data analysis (at least 2). [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Most of the signal strength is around 5 or 6 units.\n",
      "2. A few signals are like outliers with of the signal strength is around 2 and 8 units.\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Most of the signal strength is around 5 or 6 units.\")\n",
    "print(\"2. A few signals are like outliers with of the signal strength is around 2 and 8 units.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2. Data preprocessing [7 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##A. Split the data into X & Y. [1 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = signals_df.values[:,:11]  ## Features\n",
    "y = signals_df.values[:,11] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##B. Split the data into train & test with 70:30 proportion.[1 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data in test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##C. Print shape of all the 4 variables and verify if train and test data is in sync. [1 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.shape\n",
    "#X_test.shape\n",
    "#y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##D. Normalise the train and test data with appropriate method. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##E. Transform Labels into format acceptable by Neural Network [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(X[:8,1], '... will now become: ')\n",
    "\n",
    "label_X_country_encoder = LabelEncoder()\n",
    "X[:,1] = label_X_country_encoder.fit_transform(X[:,1])\n",
    "print(X[:8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Model Training & Evaluation using Neural Network [13 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A. Design a Neural Network to train a classifier. [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# The amount of nodes (dimensions) in hidden layer should be the average of input and output layers, in this case 6.\n",
    "# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n",
    "classifier.add(Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add 1st hidden layer\n",
    "classifier.add(Dense(6, activation='sigmoid', kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "# Notice that we do not need to specify input dim. \n",
    "# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n",
    "# We use the sigmoid because we want probability outcomes\n",
    "classifier.add(Dense(1, activation = 'sigmoid', kernel_initializer='uniform')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer with default learning rate\n",
    "# sgd_optimizer = tf.keras.optimizers.SGD()\n",
    "# Compile the model\n",
    "classifier.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## B. Train the classifier using previously designed Architecture [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train,           \n",
    "          validation_data=(X_test,y_test),\n",
    "          epochs=100,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## C. Plot 2 separate visuals. [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_model1 = ((cm1[0][0]+cm1[1][1])*100)/(cm1[0][0]+cm1[1][1]+cm1[0][1]+cm1[1][0])\n",
    "print (accuracy_model1, '% of testing data was classified correctly')\n",
    "79.75 % of testing data was classified correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## i. Training Loss and Validation Loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['train_loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,35)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ii. Training Accuracy and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['acc']\n",
    "loss_val = history.history['val_acc']\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## D. Design new architecture/update existing architecture in attempt to improve the performance of the model. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ANN\n",
    "classifier = Sequential()\n",
    "# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n",
    "classifier.add(Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the hidden layer\n",
    "# Notice that we do not need to specify input dim. \n",
    "classifier.add(Dense(activation = 'relu', units=6, kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "# Notice that we do not need to specify input dim. \n",
    "# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n",
    "# We use the sigmoid because we want probability outcomes\n",
    "classifier.add(Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## E. Plot visuals as in Q3.C and share insights about difference observed in both the models. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train,           \n",
    "          validation_data=(X_test,y_test),\n",
    "          epochs=100,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the confusion Matrix, we need to convert the probabilities that a customer will leave the bank into the form true or false. \n",
    "# So we will use the cutoff value 0.5 to indicate whether they are likely to exit or not.\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(y_test, y_pred)\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_model2 = ((cm2[0][0]+cm2[1][1])*100)/(cm2[0][0]+cm2[1][1]+cm2[0][1]+cm2[1][0])\n",
    "print (accuracy_model2, '% of testing data was classified correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Part B -PROJECT OBJECTIVE: To build a digit classifier on the SVHN (Street View Housing Number) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1. Data Import and Exploration [5 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A. Read the .h5 file and assign to a variable. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('Autonomous_Vehicles_SVHN_single_grey1.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B. Print all the keys from the .h5 file. [1 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"X_test\": shape (18000, 32, 32), type \"<f4\">"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = hf.get('X_test')\n",
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C. Split the data into X_train, X_test, Y_train, Y_test [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = hf.get('X_test')\n",
    "X_train_df = hf.get('X_train')\n",
    "y_test_df = hf.get('y_test')\n",
    "y_train_df = hf.get('y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2. Data Visualisation and preprocessing [13 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A. Print shape of all the 4 data split into x, y, train, test to verify if x & y is in sync. [1 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data in test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape\n",
    "#X_test.shape\n",
    "#y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B. Visualise first 10 images in train data and print its corresponding labels. [4 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    plt.imshow(X_train[x])    # show first number in the dataset\n",
    "    plt.show()\n",
    "    print('Label: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C. Reshape all the images with appropriate shape update the data in same variable. [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping X data: (n, 28, 28) => (n, 784)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D. Normalise the images i.e. Normalise the pixel values. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E. Transform Labels into format acceptable by Neural Network [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y data into categorical (one-hot encoding)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F. Print total Number of classes in the Dataset. [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3. Model Training & Evaluation using Neural Network [12 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A. Design a Neural Network to train a classifier. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.add(Dense(50, input_shape = (784, )))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dense(50))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dense(50))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dense(50))\n",
    "  model.add(Activation('sigmoid'))\n",
    "  model.add(Dense(10))\n",
    "  model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#B. Train the classifier using previously designed Architecture (Use best suitable parameters). [3 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C. Evaluate performance of the model with appropriate metrics. [2 Marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D. Plot the training loss, validation loss vs number of epochs and training accuracy, validation accuracy vs number of epochs plot and write your\n",
    "#observations on the same. [4 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['train_loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,35)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['acc']\n",
    "loss_val = history.history['val_acc']\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
